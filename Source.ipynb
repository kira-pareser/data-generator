{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "MXWyuwN_ACsx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2HrQXvRcE_5H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification, make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import f1_score, r2_score\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Filter out the ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=Warning, module=\"sklearn\")"
      ],
      "metadata": {
        "id": "AsmwXIhKYejx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper function"
      ],
      "metadata": {
        "id": "3NEb0AQYBufO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hàm hiệu chỉnh tham số khởi tạo dữ liệu\n"
      ],
      "metadata": {
        "id": "5RTOgcv1BxVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo dữ liệu cho mô hình Regression\n",
        "# Generate data with informant features\n",
        "def generate_data(n_samples=1000, n_informant_features=20):\n",
        "    informant_features = np.random.randn(n_samples, n_informant_features)      #\n",
        "    true_coefficients  = np.random.uniform(0.8,1.3, size=n_informant_features) # hệ số w trong y = wx + b\n",
        "    target = np.dot(informant_features, true_coefficients)\n",
        "    return informant_features, target\n",
        "\n",
        "# Add noise cho dữ liệu Regression\n",
        "def addNoise(data, noise_level): #data: có thể là x hoặc y, noise_level: là một số thực bất kỳ\n",
        " # đổi trực tiếp gía trị của dữ liệu đã có (không thêm dữ liệu)\n",
        "  return data+np.random.uniform(-noise_level, noise_level, size=data.shape)\n",
        "\n",
        "# Add noise cho dữ liệu Classification\n",
        "#array là y, noise_level là từ 0-1, đổi trực tiếp class của dữ liệu đã có (không thêm dữ liệu)\n",
        "def addNoise_class(array, noise_level):\n",
        "    # Determine the number of elements to switch based on noise_percent\n",
        "    num_elements_to_switch = int(len(array) * noise_level)\n",
        "\n",
        "    # Randomly choose indices to switch\n",
        "    switch_indices = np.random.choice(len(array), num_elements_to_switch, replace=False)\n",
        "\n",
        "    # Switch the values at the chosen indices\n",
        "    array[switch_indices] = 1 - array[switch_indices]\n",
        "\n",
        "    return array\n",
        "\n",
        "# Add thêm features mới mà correlate với Features đã có\n",
        "# Feature collinearity: sự ảnh hưởng nhau giữa các feature\n",
        "# informant_features: Thường là X\n",
        "# multicollinearity: số lượng FT muốn thêm\n",
        "def add_multicollinearity(informant_features, multicollinearity):\n",
        "    i=0\n",
        "    n_samples,n_informant_features=informant_features.shape\n",
        "    selected_features= np.random.randint(0, n_informant_features,multicollinearity)\n",
        "    informant_features=np.concatenate((informant_features, np.zeros((n_samples,multicollinearity))), axis=1)\n",
        "    while i<multicollinearity:\n",
        "        scaling_factor = np.random.uniform(0.5, 1)\n",
        "\n",
        "        # Generate random numbers in the range 0.8 to 1.3\n",
        "        random_numbers = np.random.uniform(0.8, 1.3, size=(n_samples, 1)).T\n",
        "\n",
        "        # Create multicollinear feature\n",
        "        tempo_feature = informant_features[:,selected_features[i]] * (scaling_factor * random_numbers)\n",
        "\n",
        "        # Add the multicollinear feature to the informant features\n",
        "        informant_features[:, i+n_informant_features ] = tempo_feature\n",
        "        i=i+1\n",
        "    return informant_features\n",
        "\n",
        "# Thêm features redundant (nhiễu)\n",
        "def addRedundant(informant_features, n_redundant):\n",
        "    n_samples,n_informant_features=informant_features.shape\n",
        "    return np.concatenate((informant_features, np.random.randn(n_samples, n_redundant)), axis=1)"
      ],
      "metadata": {
        "id": "HIgbruBZ_9_z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    y=np.array(1 / (1 + np.exp(-x)))\n",
        "    y[y>=0.5]=1\n",
        "    y[y<=0.5]=0\n",
        "    return y"
      ],
      "metadata": {
        "id": "jO46_EoRVc-R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def applyNoise(X_train, X_test, y_train, y_test, X_noise, y_noise):\n",
        "    return (addNoise(X_train, X_noise), addNoise(X_test, X_noise), addNoise(y_train, y_noise), y_test)\n",
        "def applyNoise_class(X_train, X_test, y_train, y_test,X_noise,y_noise):\n",
        "    return (addNoise(X_train, X_noise), addNoise(X_test, X_noise), addNoise_class(y_train, y_noise), y_test)\n",
        "\n",
        "def Split_applyNoise(X, y, X_noise, y_noise):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return applyNoise(X_train, X_test, y_train, y_test, X_noise, y_noise)\n",
        "def Split_applyNoise_class(X, y, X_noise, y_noise):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return applyNoise_class(X_train, X_test, y_train, y_test, X_noise, y_noise)"
      ],
      "metadata": {
        "id": "UrifmWapgjXz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Evaluate Function"
      ],
      "metadata": {
        "id": "Gu6iOKa4KF_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dont use this\n",
        "# Regression\n",
        "def _r2score(X_train, X_test, y_train, y_test, modi, parameter):\n",
        "  X_train_corr, X_test_corr = modi(X_train, X_test, y_train, y_test, parameter)\n",
        "  model = LinearRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "  print(\"default  :\", r2_score(y_test, model.predict(X_test)))\n",
        "  model.fit(X_train_corr, y_train)\n",
        "  print(\"after FS :\", r2_score(y_test, model.predict(X_test_corr)))\n",
        "  np.savez('{}_regression.npz'.format(modi.__name__), X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
        "# Classification\n",
        "def _f1score(X_train, X_test, y_train, y_test, modi, parameter):\n",
        "  X_train_corr,X_test_corr =modi(X_train, X_test, y_train, y_test, parameter)\n",
        "  model = LogisticRegression(random_state=42)\n",
        "  model.fit(X_train, y_train)\n",
        "  print(\"default  :\", f1_score(y_test, model.predict(X_test)))\n",
        "  model.fit(X_train_corr, y_train)\n",
        "  print(\"after FS :\", f1_score(y_test, model.predict(X_test_corr)))\n",
        "  np.savez('{}.npz'.format(modi.__name__), X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
      ],
      "metadata": {
        "id": "sEbz3VN3h5Y2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression\n",
        "def r2score(X,y,modi,parameter,X_noise,y_noise):\n",
        "  #modi: tên của feature selection model\n",
        "  #parameter: Tham số alpha của từng mô hình tương ứng\n",
        "  X_train, X_test, y_train, y_test = Split_applyNoise(X,y,X_noise,y_noise)\n",
        "  _r2score(X_train, X_test, y_train, y_test,modi,parameter)\n",
        "\n",
        "# Classification\n",
        "def f1score(X,y,modi,parameter,X_noise,y_noise):\n",
        "  X_train, X_test, y_train, y_test = Split_applyNoise_class(X,y,X_noise,y_noise)\n",
        "  _f1score(X_train, X_test, y_train, y_test, modi, parameter)\n"
      ],
      "metadata": {
        "id": "oF284fJqHqnq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression\n",
        "def r2score_2( X_train, X_test, y_train, y_test,modi,parameter,X_noise,y_noise):\n",
        "  #modi: tên của feature selection model\n",
        "  #parameter: Tham số alpha của từng mô hình tương ứng\n",
        "  X_train, X_test, y_train, y_test = applyNoise(X_train, X_test, y_train, y_test,X_noise,y_noise)\n",
        "  _r2score(X_train, X_test, y_train, y_test, modi, parameter)\n",
        "\n",
        "# Classification\n",
        "def f1score_2( X_train, X_test, y_train, y_test,modi,parameter,X_noise,y_noise):\n",
        "  X_train, X_test, y_train, y_test = applyNoise_class(X_train, X_test, y_train, y_test,X_noise,y_noise)\n",
        "  _f1score(X_train, X_test, y_train, y_test, modi, parameter)\n"
      ],
      "metadata": {
        "id": "jJmoFbB-XfO4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hàm cho từng mô hình Feature Selection"
      ],
      "metadata": {
        "id": "hyiSvtgUCBME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Correlation coefficient (Pearson)\n",
        "def ccFS(X_train, X_test, y_train, y_test,threshhold=0.5):\n",
        "    correlation_matrix = np.abs(pd.DataFrame(X_train).corr().values)\n",
        "    high_correlation_features = set()\n",
        "    for i in range(correlation_matrix.shape[0]):\n",
        "        for j in range(i+1, correlation_matrix.shape[0]):\n",
        "            if correlation_matrix[i, j] > threshhold:\n",
        "                high_correlation_features.add(max(i, j))\n",
        "    correlation_feature_indices = [i for i in range(correlation_matrix.shape[0]) if i not in high_correlation_features]\n",
        "    X_train_corr = X_train[:, correlation_feature_indices]\n",
        "    X_test_corr = X_test[:, correlation_feature_indices]\n",
        "    return (X_train_corr, X_test_corr)"
      ],
      "metadata": {
        "id": "gG8YFM57FEmp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "# 2. Variance Threshold\n",
        "def varianceThreshold(X_train, X_test, y_train, y_test,threshhold):\n",
        "    selector = VarianceThreshold(threshold=threshhold).fit(X_train)\n",
        "    new_cols = selector.get_support()\n",
        "    return X_train[:,new_cols],X_test[:,new_cols]"
      ],
      "metadata": {
        "id": "MR0BXgi286Ej"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Mutual Information\n",
        "from sklearn.feature_selection import (SelectKBest\n",
        "                                      ,mutual_info_regression,mutual_info_classif)\n",
        "def mutualInformation(X_train, X_test, y_train, y_test,k):\n",
        "  selector = SelectKBest(mutual_info_regression, k=k)\n",
        "  X_train_mi = selector.fit_transform(X_train, y_train)\n",
        "  X_test_mi = selector.transform(X_test)\n",
        "  return(X_train_mi, X_test_mi)\n",
        "def mutualInformation_classification(X_train, X_test, y_train, y_test,k):\n",
        "  selector = SelectKBest(mutual_info_classif, k=k)\n",
        "  X_train_mi = selector.fit_transform(X_train, y_train)\n",
        "  X_test_mi = selector.transform(X_test)\n",
        "  return(X_train_mi, X_test_mi)"
      ],
      "metadata": {
        "id": "d7BI7RKl9A2g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Forward Selection\n",
        "from sklearn.feature_selection import  SequentialFeatureSelector\n",
        "def forwardSelector(X_train, X_test, y_train, y_test,n_features_to_select):\n",
        "  forward_selector = SequentialFeatureSelector(LinearRegression(), direction='forward', n_features_to_select=n_features_to_select)\n",
        "  X_train_forward = forward_selector.fit_transform(X_train, y_train)\n",
        "  X_test_forward = forward_selector.transform(X_test)\n",
        "  return(X_train_forward, X_test_forward)\n",
        "\n",
        "def forwardSelector_classification(X_train, X_test, y_train, y_test,n_features_to_select):\n",
        "  forward_selector = SequentialFeatureSelector(LogisticRegression(max_iter=1000,random_state=42), direction='forward', n_features_to_select=n_features_to_select)\n",
        "  X_train_forward = forward_selector.fit_transform(X_train, y_train)\n",
        "  X_test_forward = forward_selector.transform(X_test)\n",
        "  return(X_train_forward, X_test_forward)\n"
      ],
      "metadata": {
        "id": "vJJkcXLZ9S_u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Recursive Feature Elimination (RFE)\n",
        "from sklearn.feature_selection import RFE as RFe\n",
        "def RFE(X_train,X_test, y_train, y_test,threshhold=0.5):\n",
        "  rfe_selector = RFe(estimator=LinearRegression(),n_features_to_select=threshhold,step=10)\n",
        "  X_train_rfe = rfe_selector.fit_transform(X_train, y_train)\n",
        "  X_test_rfe = rfe_selector.transform(X_test)\n",
        "  return (X_train_rfe,X_test_rfe)\n",
        "\n",
        "def RFE_classification(X_train,X_test, y_train, y_test,threshhold=0.5):\n",
        "  rfe_selector = RFe(estimator=LogisticRegression(random_state=42),n_features_to_select=threshhold,step=10)\n",
        "  X_train_rfe = rfe_selector.fit_transform(X_train, y_train)\n",
        "  X_test_rfe = rfe_selector.transform(X_test)\n",
        "  return (X_train_rfe,X_test_rfe)"
      ],
      "metadata": {
        "id": "aCjgp7OzZw2j"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. LASSO\n",
        "from sklearn.linear_model import  LassoCV\n",
        "def lasso(X_train,X_test, y_train, y_test,threshhold=0.5):\n",
        "  lasso_selector = SelectFromModel(LassoCV(cv=threshhold, max_iter=1000))\n",
        "  X_train_lasso = lasso_selector.fit_transform(X_train, y_train)\n",
        "  X_test_lasso = lasso_selector.transform(X_test)\n",
        "  return (X_train_lasso,X_test_lasso)"
      ],
      "metadata": {
        "id": "Dp5rEahba0QH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Ridge Regression\n",
        "from sklearn.linear_model import Ridge,RidgeCV,RidgeClassifier\n",
        "def ridge(X_train,X_test, y_train, y_test,alpha):\n",
        "  ridge_selector = SelectFromModel(RidgeCV())\n",
        "  X_train_ridge = ridge_selector.fit_transform(X_train, y_train)\n",
        "  X_test_ridge = ridge_selector.transform(X_test)\n",
        "  return (X_train_ridge,X_test_ridge)\n",
        "def ridge_classification(X_train,X_test, y_train, y_test,alpha):\n",
        "  ridge_selector = SelectFromModel(RidgeClassifier(alpha=alpha))\n",
        "  X_train_ridge = ridge_selector.fit_transform(X_train, y_train)\n",
        "  X_test_ridge = ridge_selector.transform(X_test)\n",
        "  return (X_train_ridge,X_test_ridge)"
      ],
      "metadata": {
        "id": "kA6rpGbgwfWQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Elastic Net\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "def elastic(X_train,X_test, y_train, y_test,cv):\n",
        "    elastic_net_selector = SelectFromModel(ElasticNetCV(cv=cv))\n",
        "    X_train_elastic_net = elastic_net_selector.fit_transform(X_train, y_train)\n",
        "    X_test_elastic_net = elastic_net_selector.transform(X_test)\n",
        "    return(X_train_elastic_net,X_test_elastic_net)\n"
      ],
      "metadata": {
        "id": "_uYOzZUrBJfL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Random Forest\n",
        "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
        "def randomForest(X_train,X_test, y_train, y_test,n_estimators):\n",
        "    rf_selector = SelectFromModel(RandomForestRegressor(n_estimators=n_estimators, random_state=42))\n",
        "    X_train_rf = rf_selector.fit_transform(X_train, y_train)\n",
        "    X_test_rf = rf_selector.transform(X_test)\n",
        "    return(X_train_rf,X_test_rf)\n",
        "def randomForest_classification(X_train,X_test, y_train, y_test,n_estimators):\n",
        "    rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=n_estimators, random_state=42))\n",
        "    X_train_rf = rf_selector.fit_transform(X_train, y_train)\n",
        "    X_test_rf = rf_selector.transform(X_test)\n",
        "    return(X_train_rf,X_test_rf)\n"
      ],
      "metadata": {
        "id": "coPlgbc3EX5K"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. GBM\n",
        "from sklearn.ensemble import  GradientBoostingClassifier,GradientBoostingRegressor\n",
        "def gbm(X_train,X_test, y_train, y_test,n_estimators):\n",
        "  gbm_selector = SelectFromModel(GradientBoostingRegressor(n_estimators=n_estimators, random_state=42))\n",
        "  X_train_gbm = gbm_selector.fit_transform(X_train, y_train)\n",
        "  X_test_gbm = gbm_selector.transform(X_test)\n",
        "  return (X_train_gbm,X_test_gbm)\n",
        "def gbm_classification(X_train,X_test, y_train, y_test,n_estimators):\n",
        "  gbm_selector = SelectFromModel(GradientBoostingClassifier(n_estimators=n_estimators, random_state=42))\n",
        "  X_train_gbm = gbm_selector.fit_transform(X_train, y_train)\n",
        "  X_test_gbm = gbm_selector.transform(X_test)\n",
        "  return (X_train_gbm,X_test_gbm)"
      ],
      "metadata": {
        "id": "Lt4ingL-CI-f"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Factor Analysis\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "def factorAnalysis(X_train,X_test, y_train, y_test,n_components):\n",
        "  fa_transformer = FactorAnalysis(n_components=n_components, random_state=42)\n",
        "  X_train_fa = fa_transformer.fit_transform(X_train)\n",
        "  X_test_fa = fa_transformer.transform(X_test)\n",
        "  return (X_train_fa,X_test_fa)"
      ],
      "metadata": {
        "id": "fxIZIEIFE_DN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. PCA\n",
        "from sklearn.decomposition import PCA\n",
        "def pca(X_train,X_test, y_train, y_test,n_components):\n",
        "  pca_transformer = PCA(n_components=n_components, random_state=42)\n",
        "  X_train_pca = pca_transformer.fit_transform(X_train)\n",
        "  X_test_pca = pca_transformer.transform(X_test)\n",
        "  return (X_train_pca,X_test_pca)"
      ],
      "metadata": {
        "id": "M_2IkcWc7EeO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. ICA\n",
        "from sklearn.decomposition import FastICA\n",
        "def ica(X_train,X_test, y_train, y_test,n_components):\n",
        "  ica_transformer = FastICA(n_components=n_components, random_state=42)\n",
        "  X_train_ica = ica_transformer.fit_transform(X_train)\n",
        "  X_test_ica = ica_transformer.transform(X_test)\n",
        "  return (X_train_ica,X_test_ica)"
      ],
      "metadata": {
        "id": "cQsZ63jhW4op"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Khởi tạo dữ liệu và đánh giá"
      ],
      "metadata": {
        "id": "G0zfhbwxXiVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Correlation Coefficient (Pearson)"
      ],
      "metadata": {
        "id": "NxljKIMiX-Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Regression\n",
        "X,y = generate_data(n_samples=1000, n_informant_features=50)\n",
        "X=add_multicollinearity(X,multicollinearity=100)\n",
        "r2score(X,y,ccFS,0.3,0.25,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MHWMPppFFIN",
        "outputId": "14f238b5-6eb0-4ab9-9116-9090ffc10371"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.8834797067089832\n",
            "after FS : 0.9534578724841646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Classification\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=50,   # Number of features\n",
        "    n_informative=50,  # Number of informative features\n",
        "    n_redundant=0,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "X=add_multicollinearity(X,100)\n",
        "\n",
        "f1score(X,y,ccFS,0.3,1,0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8aTn7XK2E8c",
        "outputId": "08b7d5ce-e1f5-43f4-a586-da8970028e2a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.6564102564102564\n",
            "after FS : 0.6829268292682927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Variance Threshold"
      ],
      "metadata": {
        "id": "BLbQIz91iBLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def idTypeValue(true_value,shape):\n",
        "  ids=np.random.randint(0, len(true_value), shape)\n",
        "  ids_value=np.copy(ids)\n",
        "  for i,value in enumerate(true_value):\n",
        "    ids_value[ids_value==i] =value\n",
        "  return (ids,ids_value)"
      ],
      "metadata": {
        "id": "-B3WTEMkI4wj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_id_data_type= 40\n",
        "n_float_data_type=20\n",
        "\n",
        "true_coefficients  =np.concatenate((np.random.uniform(0.1,0.2, size=n_id_data_type),np.random.uniform(0.8,1.3, size=n_float_data_type))) # hệ số w trong y = wx + b\n",
        "#Create Train dataset\n",
        "X_train,X_train_value=idTypeValue([10,6],(800,n_id_data_type))\n",
        "random_floats = np.random.uniform(-10, 10, (800, n_float_data_type))\n",
        "X_train = np.concatenate((X_train,random_floats),axis=1)\n",
        "y_train = np.dot(np.concatenate((X_train_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "#Create Test dataset\n",
        "X_test,X_test_value=idTypeValue([3,6],(200,n_id_data_type))\n",
        "random_floats = np.random.uniform(-20, 20, (200, n_float_data_type))\n",
        "X_test = np.concatenate((X_test+4,random_floats),axis=1)\n",
        "y_test = np.dot(np.concatenate((X_test_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "r2score_2(X_train,X_test,y_train,y_test,varianceThreshold,0.9,0,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb1flN6hULL8",
        "outputId": "103d966b-6c87-4a77-a138-10d5421e2332"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : -0.9239270353504541\n",
            "after FS : 0.852196990809972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_id_data_type= 40\n",
        "n_float_data_type=20\n",
        "\n",
        "true_coefficients  =np.concatenate((np.random.uniform(0.1,0.2, size=n_id_data_type),np.random.uniform(0.8,1.3, size=n_float_data_type))) # hệ số w trong y = wx + b\n",
        "#Create Train dataset\n",
        "X_train,X_train_value=idTypeValue([-30,30],(800,n_id_data_type))\n",
        "random_floats = np.random.uniform(-10, 10, (800, n_float_data_type))\n",
        "X_train = np.concatenate((X_train,random_floats),axis=1)\n",
        "y_train = sigmoid(np.dot(np.concatenate((X_train_value,random_floats),axis=1), true_coefficients))\n",
        "\n",
        "#Create Test dataset\n",
        "X_test,X_test_value=idTypeValue([60,-60],(200,n_id_data_type))\n",
        "random_floats = np.random.uniform(-20, 20, (200, n_float_data_type))\n",
        "X_test = np.concatenate((X_test+4,random_floats),axis=1)\n",
        "y_test = sigmoid( np.dot(np.concatenate((X_test_value,random_floats),axis=1), true_coefficients))\n",
        "\n",
        "f1score_2(X_train,X_test,y_train,y_test,varianceThreshold,0.9,0,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag0RFfvciOb_",
        "outputId": "86ddcbe5-9842-46d6-d23c-7b721c5e7f27"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.6666666666666666\n",
            "after FS : 0.7254901960784313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Mutual Information"
      ],
      "metadata": {
        "id": "Xy6IMsc8iEH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_id_data_type= 40\n",
        "n_float_data_type=20\n",
        "\n",
        "true_coefficients = np.concatenate((np.random.uniform(0.1,0.2, size=n_id_data_type),np.random.uniform(0.8,1.3, size=n_float_data_type))) # hệ số w trong y = wx + b\n",
        "#Create Train dataset\n",
        "X_train,X_train_value=idTypeValue([10,6],(800,n_id_data_type))\n",
        "random_floats = np.random.uniform(-10, 10, (800, n_float_data_type))\n",
        "X_train = np.concatenate((X_train,random_floats),axis=1)\n",
        "y_train = np.dot(np.concatenate((X_train_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "#Create Test dataset\n",
        "X_test,X_test_value=idTypeValue([3,6],(200,n_id_data_type))\n",
        "random_floats = np.random.uniform(-20, 20, (200, n_float_data_type))\n",
        "X_test = np.concatenate((X_test+4,random_floats),axis=1)\n",
        "y_test = np.dot(np.concatenate((X_test_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "r2score_2(X_train, X_test, y_train, y_test, mutualInformation,30,0,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhKOCVkbrABB",
        "outputId": "ab6f4432-fb24-4ebe-8bca-18da179e9470"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : -1.220590587215435\n",
            "after FS : 0.37825464595848923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=100,   # Number of features\n",
        "    n_informative=50,  # Number of informative features\n",
        "    n_redundant=50,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "X=add_multicollinearity(X,100)\n",
        "\n",
        "f1score(X,y,mutualInformation_classification,50,0.1,0.15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PZghv1hemmD",
        "outputId": "2c81dfd2-fe8d-497a-fd2a-2321566b57fa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7142857142857143\n",
            "after FS : 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Forward Selection"
      ],
      "metadata": {
        "id": "D_cG0pP5iHs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Regression\n",
        "\n",
        "X,y=  generate_data(n_samples=1000, n_informant_features=20)\n",
        "X=addRedundant(X,180)\n",
        "r2score(X,y,forwardSelector,20,1,1)"
      ],
      "metadata": {
        "id": "BesQnK40FZ_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac14ec93-c216-4454-aa6b-6740673e117a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.727738380216751\n",
            "after FS : 0.7638232702464407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=200,   # Number of features\n",
        "    n_informative=20,  # Number of informative features\n",
        "    n_redundant=180,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "f1score(X,y,forwardSelector_classification,20,1,0.05)\n"
      ],
      "metadata": {
        "id": "1bQNx-ISGlnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7234f220-23c0-40e1-a35c-2ca9c9f793d3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.6994535519125683\n",
            "after FS : 0.7624309392265194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Recursive Feature Elimination (RFE)"
      ],
      "metadata": {
        "id": "jDC29cZIZkpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Regression\n",
        "\n",
        "X,y = generate_data(n_samples=1000, n_informant_features=20)\n",
        "X=addRedundant(X,180)\n",
        "r2score(X,y,RFE,20,1,1)"
      ],
      "metadata": {
        "id": "hAEvHEVDZm98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13aaaa37-d2ab-491e-98a7-a13ce202e406"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7207058720588579\n",
            "after FS : 0.7803162823583533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Classification\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=200,   # Number of features\n",
        "    n_informative=20,  # Number of informative features\n",
        "    n_redundant=180,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "f1score(X,y,RFE_classification, 20,0.5,0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "_52FvTfvLi8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0be87fd-8e0f-4e01-ad45-cf519f922dfe"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.6979166666666666\n",
            "after FS : 0.7668393782383419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Lasso"
      ],
      "metadata": {
        "id": "8n76keY4wIkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Regression\n",
        "X,y=  generate_data(n_samples=1000, n_informant_features=40)\n",
        "X=addRedundant(X,160)\n",
        "r2score(X, y, lasso, 2,0.75,2)"
      ],
      "metadata": {
        "id": "0VGrBEDHaqmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6471b3a-2314-427e-be52-ebae7f2fb4ea"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7172857564972426\n",
            "after FS : 0.758852658194994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Classification\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=200,   # Number of features\n",
        "    n_informative=40,  # Number of informative features\n",
        "    n_redundant=160,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "f1score(X,y,lasso,40,0.75,0.1)"
      ],
      "metadata": {
        "id": "ap_Fm1RNeHs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3a82fd-40f5-4757-86ec-7e0eb315ddf6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7539267015706806\n",
            "after FS : 0.8085106382978724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Ridge"
      ],
      "metadata": {
        "id": "-Hem6NDLwONt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Regression\n",
        "X,y = generate_data(n_samples=1000, n_informant_features=10)\n",
        "X = addRedundant(X,n_redundant=40)\n",
        "r2score(X, y, ridge, 0.9,0.25,8)\n"
      ],
      "metadata": {
        "id": "-ksZYDtexckQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40357bf4-2156-4251-ecec-aaec0ca1353e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7326050213267283\n",
            "after FS : 0.8297030991790406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Classification\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=100,   # Number of features\n",
        "    n_informative=40,  # Number of informative features\n",
        "    n_redundant=60,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "\n",
        "f1score(X,y,ridge_classification, 0.5,0.5,0.2)"
      ],
      "metadata": {
        "id": "Gj1e65BUPE8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a53a9cd-883d-43a8-de60-6deff2252a6b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7684210526315789\n",
            "after FS : 0.7853403141361256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Elastic Net"
      ],
      "metadata": {
        "id": "yPsFt9VR6J8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_id_data_type= 40\n",
        "n_float_data_type=20\n",
        "\n",
        "true_coefficients = np.concatenate((np.random.uniform(0.1,0.2, size=n_id_data_type),np.random.uniform(0.8,1.3, size=n_float_data_type))) # hệ số w trong y = wx + b\n",
        "#Create Train dataset\n",
        "X_train,X_train_value=idTypeValue([10,6],(800,n_id_data_type))\n",
        "random_floats = np.random.uniform(-10, 10, (800, n_float_data_type))\n",
        "X_train = np.concatenate((X_train,random_floats),axis=1)\n",
        "y_train = np.dot(np.concatenate((X_train_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "#Create Test dataset\n",
        "X_test,X_test_value=idTypeValue([3,6],(200,n_id_data_type))\n",
        "random_floats = np.random.uniform(-20, 20, (200, n_float_data_type))\n",
        "X_test = np.concatenate((X_test+4,random_floats),axis=1)\n",
        "y_test = np.dot(np.concatenate((X_test_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "r2score_2(X_train,X_test,y_train,y_test,elastic,10,0,0)"
      ],
      "metadata": {
        "id": "mA0_JHHgBGBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10f4f27c-b058-4afe-c91f-abcd1e037569"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : -0.733043125286065\n",
            "after FS : 0.9140132680122369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=200,   # Number of features\n",
        "    n_informative=40,  # Number of informative features\n",
        "    n_redundant=160,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "f1score(X,y,elastic,10,0.75,0.1)"
      ],
      "metadata": {
        "id": "kBwUB-QTHD5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab75d81-b9ac-41b4-8fad-84f91343c06b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7000000000000001\n",
            "after FS : 0.8167539267015707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Random Forest"
      ],
      "metadata": {
        "id": "t13_FSba6KCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_id_data_type= 40\n",
        "n_float_data_type=20\n",
        "\n",
        "true_coefficients  =np.concatenate((np.random.uniform(0.1,0.2, size=n_id_data_type),np.random.uniform(0.8,1.3, size=n_float_data_type))) # hệ số w trong y = wx + b\n",
        "#Create Train dataset\n",
        "X_train,X_train_value=idTypeValue([10,6],(800,n_id_data_type))\n",
        "random_floats = np.random.uniform(-10, 10, (800, n_float_data_type))\n",
        "X_train = np.concatenate((X_train,random_floats),axis=1)\n",
        "y_train = np.dot(np.concatenate((X_train_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "#Create Test dataset\n",
        "X_test,X_test_value=idTypeValue([3,6],(200,n_id_data_type))\n",
        "random_floats = np.random.uniform(-20, 20, (200, n_float_data_type))\n",
        "X_test = np.concatenate((X_test+4,random_floats),axis=1)\n",
        "y_test = np.dot(np.concatenate((X_test_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "r2score_2(X_train,X_test,y_train,y_test,randomForest,100,0,0)"
      ],
      "metadata": {
        "id": "GUrBboLTK1-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0d6802-d7e4-4614-d5ba-7f3e5219bd9d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : -0.7816656851779029\n",
            "after FS : 0.8585368720118308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=200,   # Number of features\n",
        "    n_informative=40,  # Number of informative features\n",
        "    n_redundant=0,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "X=addRedundant(X,160)\n",
        "f1score(X,y,randomForest_classification,100,0.75,0.2)"
      ],
      "metadata": {
        "id": "C3bt_NLsLSPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369e8d47-5642-4566-a699-18f81f01abc9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.6792452830188679\n",
            "after FS : 0.7281553398058253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. GBM"
      ],
      "metadata": {
        "id": "FHL3e2s4vKXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_id_data_type= 40\n",
        "n_float_data_type=20\n",
        "\n",
        "true_coefficients  =np.concatenate((np.random.uniform(0.1,0.2, size=n_id_data_type),np.random.uniform(0.8,1.3, size=n_float_data_type))) # hệ số w trong y = wx + b\n",
        "#Create Train dataset\n",
        "X_train,X_train_value=idTypeValue([10,6],(800,n_id_data_type))\n",
        "random_floats = np.random.uniform(-10, 10, (800, n_float_data_type))\n",
        "X_train = np.concatenate((X_train,random_floats),axis=1)\n",
        "y_train = np.dot(np.concatenate((X_train_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "#Create Test dataset\n",
        "X_test,X_test_value=idTypeValue([3,6],(200,n_id_data_type))\n",
        "random_floats = np.random.uniform(-20, 20, (200, n_float_data_type))\n",
        "X_test = np.concatenate((X_test+4,random_floats),axis=1)\n",
        "y_test = np.dot(np.concatenate((X_test_value,random_floats),axis=1), true_coefficients)\n",
        "\n",
        "r2score_2(X_train,X_test,y_train,y_test,gbm,100,0,0)"
      ],
      "metadata": {
        "id": "C_QXqQSvybEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b6c783-6b61-4715-e3a7-552172fce44d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : -0.861312711670335\n",
            "after FS : 0.850827042714563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=200,   # Number of features\n",
        "    n_informative=40,  # Number of informative features\n",
        "    n_redundant=160,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "f1score(X,y,gbm_classification,40,0.75,0.1)"
      ],
      "metadata": {
        "id": "Ik3KQiJgvUP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e96319a-baf4-48d7-ea3b-4d88254be8ae"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7486631016042781\n",
            "after FS : 0.8397790055248618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Factor Analysis"
      ],
      "metadata": {
        "id": "Y-a9dCqq0t_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=  generate_data(n_samples=1000, n_informant_features=20)\n",
        "X=add_multicollinearity(X,multicollinearity=80)\n",
        "r2score(X,y,factorAnalysis,20,1,10)"
      ],
      "metadata": {
        "id": "i6ZUjpv-4Wm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7657de3c-88e2-4e40-f897-cd3b17e0acad"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7063078562280405\n",
            "after FS : 0.8089911586314348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=100,   # Number of features\n",
        "    n_informative=20,  # Number of informative features\n",
        "    n_redundant=0,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "X=add_multicollinearity(X,80)\n",
        "f1score(X,y,factorAnalysis,40,3,0.3)"
      ],
      "metadata": {
        "id": "xrAcPysT_tBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3eab4d0-73a0-4391-b8f9-b8373a03cd25"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.6137566137566138\n",
            "after FS : 0.7333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. PCA"
      ],
      "metadata": {
        "id": "dXI1Jjts62qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Regression\n",
        "\n",
        "X,y=  generate_data(n_samples=1000, n_informant_features=20)\n",
        "X=add_multicollinearity(X,multicollinearity=180)\n",
        "#X=addRedundant(X,20)\n",
        "print(X.shape)\n",
        "r2score(X,y,pca,20,2,1)\n",
        "\n"
      ],
      "metadata": {
        "id": "r7nGv2rL6_Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8e04f0-9942-4be6-d02f-c1470db2a428"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 200)\n",
            "default  : 0.7369638733490765\n",
            "after FS : 0.8142097326971622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Classification\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=100,   # Number of features\n",
        "    n_informative=100,  # Number of informative features\n",
        "    n_redundant=0,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "X=add_multicollinearity(X,100)\n",
        "\n",
        "f1score(X,y,pca,100,2,0.1)\n"
      ],
      "metadata": {
        "id": "2BIlyJRIB0sp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ac0120-3d2f-4973-970b-7657a1183b57"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7171717171717172\n",
            "after FS : 0.7653061224489796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. ICA"
      ],
      "metadata": {
        "id": "lWMSevGdOfS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Regression\n",
        "\n",
        "X,y=  generate_data(n_samples=1000, n_informant_features=100)\n",
        "X=add_multicollinearity(X,multicollinearity=100)\n",
        "r2score(X,y,ica,100,1,2)"
      ],
      "metadata": {
        "id": "Zsg2i3OqVY9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ae0e29-1562-433b-9acc-858662e05c37"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7721475272160343\n",
            "after FS : 0.8008790634811767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo bộ dữ liệu cho mô hình Classification\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,  # Number of samples\n",
        "    n_features=100,   # Number of features\n",
        "    n_informative=100,  # Number of informative features\n",
        "    n_redundant=0,    # Number of redundant features\n",
        "    n_classes=2,      # Number of classes\n",
        "    random_state=42   # Random seed for reproducibility\n",
        ")\n",
        "X=add_multicollinearity(X,100)\n",
        "f1score(X,y,ica,100,1,0.1)"
      ],
      "metadata": {
        "id": "1tRQbxUxaMOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524c2b11-0502-46d9-f212-f7b00d6c1edc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default  : 0.7609756097560975\n",
            "after FS : 0.7759562841530053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/z.zip /content/z\n",
        "from google.colab import files\n",
        "files.download(\"/content/z.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "5mV5vYKrOGK-",
        "outputId": "c6f47c8b-7813-4b35-f93b-ccc92eb9676b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/z/ (stored 0%)\n",
            "  adding: content/z/elastic_regression.npz (deflated 63%)\n",
            "  adding: content/z/ridge_regression.npz (deflated 4%)\n",
            "  adding: content/z/RFE_regression.npz (deflated 4%)\n",
            "  adding: content/z/mutualInformation_regression.npz (deflated 63%)\n",
            "  adding: content/z/ica_regression.npz (deflated 4%)\n",
            "  adding: content/z/forwardSelector_classification.npz (deflated 4%)\n",
            "  adding: content/z/ccFS_classification.npz (deflated 4%)\n",
            "  adding: content/z/varianceThreshold_regression.npz (deflated 63%)\n",
            "  adding: content/z/gbm_regression.npz (deflated 63%)\n",
            "  adding: content/z/forwardSelector_regression.npz (deflated 4%)\n",
            "  adding: content/z/ridge_classification.npz (deflated 4%)\n",
            "  adding: content/z/lasso_regression.npz (deflated 4%)\n",
            "  adding: content/z/varianceThreshold_classification.npz (deflated 64%)\n",
            "  adding: content/z/RFE_classification.npz (deflated 4%)\n",
            "  adding: content/z/mutualInformation_classification.npz (deflated 4%)\n",
            "  adding: content/z/ccFS_regression.npz (deflated 4%)\n",
            "  adding: content/z/factorAnalysis_regression.npz (deflated 4%)\n",
            "  adding: content/z/pca_classification.npz (deflated 4%)\n",
            "  adding: content/z/factorAnalysis_classification.npz (deflated 4%)\n",
            "  adding: content/z/lasso_classification.npz (deflated 4%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_242b855f-69fa-4ec3-b650-6081e4655ec5\", \"z.zip\", 29649686)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}